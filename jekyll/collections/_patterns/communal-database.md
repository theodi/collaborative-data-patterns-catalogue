---
category: project-types
title: Communal Database
nav_order: 1
description: >-
    The work to compile and maintain a database that would be useful to a community of organisation is costly and time-intensive
context: >-
    Many organisations and communities often use the same data to support their products, services and interests. Collecting and maintaining the data can be expensive and work might be duplicated across organisations and communities.
solution: |-
    Create a collaborative maintenance project that allows contributors to work together to maintain a database that is valuable to them all.
examples:
    
---

Increasing access to data, eg by publishing it under an open licence, can allow a wider community of people and organisations to benefit from it. But the effort required to collect and maintain the data is a key consideration in making that access sustainable.

Sharing the work of maintaining the data can help spread those costs across a wider community, while allowing users to collaborate to improve its quality.

This type of project involves developing a useful database, starting from a **Fixed Schema** â€“ but this schema likely to change over time. An **Evolving Schema** will allow the project to adapt to the shared needs of its contributor community.

The work of contributors will involve not just completing tasks to populate a dataset, as in a **Collaborative Cataloguing **project. The data maintenance will also be shared across the community.

The database is likely to contain reference data that describes an area of shared interest, rather than a series of observations that are collected in an **Observation Pool**.

A **Shared Directory** is one example of a Communal Database, but usually with a more restricted focus. A Communal Database about music would contain lists of artists, albums, tracks and musicians, as well as information about their connections.

The main difference between a **Communal Database** and a **Knowledge Commons** is that in the latter, there is much more devolved responsibility for making decisions and managing the community.

The data maintenance work might be spread across people who are not data experts and are busy with other tasks. So a good **Onboarding Process** and **Learning Curve** is important. A clear review process will be important to help maintain quality. **Retrospective Reviews** supported by **Field Validation** to capture common data errors will be important. **Escalating Blocking** may be required to keep the community on track.

Supporting **Extendable Tooling **and **Bulk Updates **may help to support users in the curation of the data.

If you **Deliver Individual Value** to contributors, whether they are individuals or organisations, then the project will deliver value from the start and not just when it has critical mass.

The changing nature of the work involved in maintaining the dataset means that **Microtasks** might be helpful in supporting and encouraging maintenance work.

It is important to have **Clearly Defined Roles** as work is shared across a distributed team. **Transparent Stewardship, **well-defined **Published Policies** and **Clear Licensing** will also build trust in the data and the project.
